name = "ascii-e2-alpha-64-qwen3-4b-instruct-2507"
model = "Qwen/Qwen3-4B-Instruct-2507"
max_steps = 300
batch_size = 512
rollouts_per_example = 16
trajectory_strategy = "interleaved"
learning_rate = 1e-6
lora_alpha = 64

[sampling]
max_tokens = 5000

[[env]]
id = "13point5/ascii-align"

[val]
num_examples = 32
rollouts_per_example = 3
interval = 10

[wandb]
project = "ascii-align"
name = "ascii-e2-alpha-64-qwen3-4b-instruct-2507"
entity = "13point5-labs"
